{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpTBUnJhV-QO"
      },
      "source": [
        "# **Aprendizaje Automático - Regresión**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhAcnrTV-vK"
      },
      "source": [
        "- Francisco Prados Abad\n",
        "- Paola León Tarife\n",
        "- Julia de Enciso García\n",
        "- Paula Samper López\n",
        "- Camino Rodríguez Pérez-Carral\n",
        "- Lucía Yan Wu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEBkDxiqjcLs"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook hemos utilizado distintos modelos para resolver la tarea de regresión, donde tenemos que predecir el valor de la variable *ScoreRiesgo*."
      ],
      "metadata": {
        "id": "556kkTBzqOHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, fijamos la semilla y hacemos los imports necesarios."
      ],
      "metadata": {
        "id": "2B1iHA-4q7N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-24T18:38:21.196476Z",
          "start_time": "2024-10-24T18:38:21.167931Z"
        },
        "id": "mV0QQIlZ0yif"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "# Set seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huqF-TDJm93X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor, StackingRegressor, BaggingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scikeras.wrappers import KerasRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWu-MzExrO9X"
      },
      "source": [
        "### Cargar los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora cargamos los datos que ya han sido preprocesados."
      ],
      "metadata": {
        "id": "tverjDPYrT2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSrLZY2LnEpr"
      },
      "outputs": [],
      "source": [
        "# Accedemos a las bases de datos procesadas\n",
        "X_train = pd.read_csv('data/regresión/X_train.csv')\n",
        "y_train = pd.read_csv('data/regresión/y_train.csv')\n",
        "X_test = pd.read_csv('data/regresión/X_test.csv')\n",
        "y_test = pd.read_csv('data/regresión/y_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az8L69wYi8N_"
      },
      "source": [
        "# Tarea de Regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación pasamos a explicar los modelos que hemos probado. Hemos probado modelos simples, como la regresión lineal y un árbol de decisión. También hemos utilizado redes de neuronas, y hemos montado distintos ensembles para intentar mejorar nuestros resultados.\n",
        "\n",
        "Ajustaremos los hiperparámetros de los modelos mediante RandomizedSearchCV y GridSearch CV.\n",
        "\n",
        "El error que hemos utilizado para comparar los resultados de los distintos modelos es el Mean Absolute Error (MAE)."
      ],
      "metadata": {
        "id": "Qoa3BbOBrnlr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w88qqV7Kt1tB"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer modelo que probamos fue la regresión lineal, que es un modelo bastante simple. Hemos ajustado el parámetro *n_jobs* mediante GridSearchCV, que define el grado de paralelismo utilizado."
      ],
      "metadata": {
        "id": "cBIfwSEJsjTw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "KKS26imT-1U1",
        "outputId": "b39d057b-7e0e-4621-d457-dded9d3dcf22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LinearRegression(),\n",
              "             param_grid={&#x27;n_jobs&#x27;: [0, 50, 100, 200]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LinearRegression(),\n",
              "             param_grid={&#x27;n_jobs&#x27;: [0, 50, 100, 200]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LinearRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(n_jobs=0)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(n_jobs=0)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
              "             param_grid={'n_jobs': [0, 50, 100, 200]},\n",
              "             scoring='neg_mean_absolute_error', verbose=False)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Definimos el modelo\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Definir distintos valores de los parámetros\n",
        "param_grid_lr = {'n_jobs': [0, 50, 100, 200]}\n",
        "\n",
        "rand_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_lr.fit(X_train, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ0DqJFe_BrX",
        "outputId": "330acc82-d34b-4b93-e8e5-3160164a7653"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.236717540371663"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_lr.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxVt1Dv8_Doz",
        "outputId": "d11f4b75-5108-49c5-b09c-3f28513c17c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_jobs': 0}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_lr.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExowDygY_JE-",
        "outputId": "833d48e7-0d4e-41b4-87bf-9acd9dd0b531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.19501157, 0.13257389, 0.05515728, 0.069416  ]),\n",
              " 'std_fit_time': array([0.06055531, 0.04352395, 0.01287706, 0.01999354]),\n",
              " 'mean_score_time': array([0.00697765, 0.00766096, 0.00558639, 0.00429897]),\n",
              " 'std_score_time': array([0.00325945, 0.00351325, 0.00248819, 0.00238992]),\n",
              " 'param_n_jobs': masked_array(data=[0, 50, 100, 200],\n",
              "              mask=[False, False, False, False],\n",
              "        fill_value=999999),\n",
              " 'params': [{'n_jobs': 0}, {'n_jobs': 50}, {'n_jobs': 100}, {'n_jobs': 200}],\n",
              " 'split0_test_score': array([-3.24093687, -3.24093687, -3.24093687, -3.24093687]),\n",
              " 'split1_test_score': array([-3.22058881, -3.22058881, -3.22058881, -3.22058881]),\n",
              " 'split2_test_score': array([-3.2172527, -3.2172527, -3.2172527, -3.2172527]),\n",
              " 'split3_test_score': array([-3.26204418, -3.26204418, -3.26204418, -3.26204418]),\n",
              " 'split4_test_score': array([-3.24276516, -3.24276516, -3.24276516, -3.24276516]),\n",
              " 'mean_test_score': array([-3.23671754, -3.23671754, -3.23671754, -3.23671754]),\n",
              " 'std_test_score': array([0.0163391, 0.0163391, 0.0163391, 0.0163391]),\n",
              " 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_lr.cv_results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SduNMvyk_aj2"
      },
      "source": [
        "#### Best LR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, probamos el mejor modelo en los datos de test."
      ],
      "metadata": {
        "id": "T3UvNVHstNDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvVUGI0SoWq",
        "outputId": "1c79e001-c67c-456d-a0c9-c81b0c6d5487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 3.2613459427699567\n"
          ]
        }
      ],
      "source": [
        "# Definimos el modelo\n",
        "lr = LinearRegression(n_jobs=0)\n",
        "\n",
        "# Entrenamos nuestro modelo\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El MAE obtenido es bastante alto, de 3.26. Esto nos indica que la relación que existe entre *ScoreRiesgo* y el resto de atributos no es una relación lineal."
      ],
      "metadata": {
        "id": "NFvhRrHvt1QB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlLcDsx0wn4I"
      },
      "source": [
        "### Árbol de decision para regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente modelo que hemos probado es un árbol de decisión.\n",
        "\n",
        "Hemos ajustado los siguientes hiperparámetros mediante *RandomizedSearchCV*:\n",
        "\n",
        "\n",
        "*   **max_depth**: profundidad máxima del árbol de decisión.\n",
        "*   **min_samples_leaf**: número mínimo de datos que hacen falta para formar una hoja.\n",
        "*   **max_features**: porcentaje de los atributos que se tienen en cuenta para dividir un nodo.\n",
        "*   **min_samples_split**: número de datos que hacen falta para dividir un nodo."
      ],
      "metadata": {
        "id": "n7nrRKKFuD2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RhDjB1OIoo2",
        "outputId": "b54eeadf-7614-40b4-98ab-e8fde55db1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-2.527342292965824\n",
            "{'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 0.5, 'max_depth': 12}\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Definir distintos valores de los parámetros\n",
        "param_grid_rf = {'max_depth' : [4, 8, 12, None],\n",
        "               'min_samples_leaf': [1, 3, 5],\n",
        "               'max_features': [0.5, 1.0],\n",
        "               'min_samples_split': [2, 5]}\n",
        "\n",
        "# Busqueda de hiperparámetros\n",
        "rand_DT = RandomizedSearchCV(estimator=dt, param_distributions=param_grid_rf, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_DT.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# resultados\n",
        "best_score = rand_DT.best_score_\n",
        "best_params = rand_DT.best_params_\n",
        "\n",
        "print(best_score)\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iuBuJiSw5P0"
      },
      "source": [
        "#### Best DT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras ajustar los hiperparámetros, entrenamos el modelo."
      ],
      "metadata": {
        "id": "qF3LfaOjwDw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-TeKes_uIKV",
        "outputId": "ff5d5e10-ca8f-40fe-8b37-5b7de8bb747c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 2.5256624217676213\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeRegressor(random_state=42, max_features=0.5, min_samples_split=5, min_samples_leaf=5, max_depth=12)\n",
        "\n",
        "dt.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El MAE que hemos obtenido en los datos de test es de 2.52. Hemos mejorado el error respecto al modelo de regresión lineal, pero sigue siendo necesario probar otros modelos que capten mejor las relaciones entre los distintos atributos."
      ],
      "metadata": {
        "id": "x-OZcMpCwM2G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va_SIjD2xN9G"
      },
      "source": [
        "### Red de Neuronas (Keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a probar una red de neuronas de *Keras* sencilla de dos capas.\n",
        "\n",
        "Hemos ajustado los hiperparámetros mediante *KerasRegressor*, que permite utilizar *RandomizedSearchCV* con la red aunque no sea un modelo de *sci-kit learn*. Los hiperparámetros que hemos ajustado son:\n",
        "\n",
        "\n",
        "*   **batch_size:** tamaño del batch.\n",
        "*   **epochs:** número de epochs para entrenar el modelo.\n",
        "*   **model__neurons_layer1:** número de neuronas en la primera capa oculta de la red.\n",
        "*   **model__neurons_layer2:** número de neuronas en la segunda capa oculta de la red.\n",
        "*   **model__optimizer:** optimizador del modelo para el ajuste de parámetros en el entrenamiento.\n"
      ],
      "metadata": {
        "id": "ZxdmL55c2DVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOg1J2Zv0GdW",
        "outputId": "21830065-8589-473a-a506-2c45c0b09402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Best MAE: 1.6773001161649308\n",
            "Best params: {'model__optimizer': 'adam', 'model__neurons_layer2': 32, 'model__neurons_layer1': 128, 'epochs': 200, 'batch_size': 64}\n"
          ]
        }
      ],
      "source": [
        "# Función que construye el modelo\n",
        "def build_model(neurons_layer1=64, neurons_layer2=32, optimizer='adam'):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(X_train.shape[1],)),  # Capa de entrada\n",
        "        layers.Dense(neurons_layer1, activation='relu'),  # Primera capa oculta\n",
        "        layers.Dense(neurons_layer2, activation='relu'),  # Segunda capa oculta\n",
        "        layers.Dense(1)  # Capa de salida\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='mean_absolute_error')  # Compilar el modelo\n",
        "    return model\n",
        "\n",
        "# Envolver el modelo en KerasRegressor\n",
        "model = KerasRegressor(model=build_model, verbose=0)\n",
        "\n",
        "# Definir los parámetros para la búsqueda en cuadrícula\n",
        "param_grid = {\n",
        "    'batch_size': [16, 32, 64],         # Probar diferentes tamaños de batch\n",
        "    'epochs': [50, 100, 200],           # Diferentes épocas\n",
        "    'model__neurons_layer1': [32, 64, 128],  # Cantidad de neuronas en la primera capa\n",
        "    'model__neurons_layer2': [16, 32, 64],   # Cantidad de neuronas en la segunda capa\n",
        "    'model__optimizer': ['adam', 'rmsprop']  # Diferentes optimizadores\n",
        "}\n",
        "\n",
        "# Configurar el GridSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
        "                                   n_iter=5, cv=3, scoring='neg_mean_absolute_error', verbose=1)\n",
        "\n",
        "# Ejecutar la búsqueda\n",
        "random_search_result = random_search.fit(X_train, y_train)\n",
        "\n",
        "# Mejor resultado\n",
        "print(f\"Best MAE: {-random_search_result.best_score_}\")\n",
        "print(f\"Best params: {random_search_result.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras obtener los hiperparámetros, entrenamos el modelo. Podemos ver que el MAE obtenido en el conjunto de test es de 1.654, una mejora considerable respecto a los modelos anteriores."
      ],
      "metadata": {
        "id": "NR5CdRa33cGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qg8VxNkeBNN",
        "outputId": "a9f85259-a09e-42c2-b19e-80bcc66589cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 21.6568\n",
            "Epoch 2/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3619\n",
            "Epoch 3/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7172\n",
            "Epoch 4/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2510\n",
            "Epoch 5/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.0757\n",
            "Epoch 6/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.9721\n",
            "Epoch 7/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9159\n",
            "Epoch 8/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.9035\n",
            "Epoch 9/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8710\n",
            "Epoch 10/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8390\n",
            "Epoch 11/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8280\n",
            "Epoch 12/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8127\n",
            "Epoch 13/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7974\n",
            "Epoch 14/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.7849\n",
            "Epoch 15/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.7788\n",
            "Epoch 16/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.7828\n",
            "Epoch 17/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7687\n",
            "Epoch 18/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7795\n",
            "Epoch 19/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7673\n",
            "Epoch 20/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7681\n",
            "Epoch 21/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7663\n",
            "Epoch 22/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7435\n",
            "Epoch 23/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7583\n",
            "Epoch 24/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.7440\n",
            "Epoch 25/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.7276\n",
            "Epoch 26/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7413\n",
            "Epoch 27/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7336\n",
            "Epoch 28/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7097\n",
            "Epoch 29/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7008\n",
            "Epoch 30/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7129\n",
            "Epoch 31/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6981\n",
            "Epoch 32/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7248\n",
            "Epoch 33/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6929\n",
            "Epoch 34/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6986\n",
            "Epoch 35/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7318\n",
            "Epoch 36/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6983\n",
            "Epoch 37/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7000\n",
            "Epoch 38/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6809\n",
            "Epoch 39/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6778\n",
            "Epoch 40/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6856\n",
            "Epoch 41/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6974\n",
            "Epoch 42/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6943\n",
            "Epoch 43/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6663\n",
            "Epoch 44/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.7003\n",
            "Epoch 45/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6812\n",
            "Epoch 46/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6741\n",
            "Epoch 47/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6604\n",
            "Epoch 48/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6649\n",
            "Epoch 49/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6838\n",
            "Epoch 50/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6896\n",
            "Epoch 51/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6713\n",
            "Epoch 52/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6808\n",
            "Epoch 53/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6820\n",
            "Epoch 54/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6591\n",
            "Epoch 55/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6800\n",
            "Epoch 56/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6774\n",
            "Epoch 57/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6584\n",
            "Epoch 58/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6599\n",
            "Epoch 59/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6634\n",
            "Epoch 60/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6480\n",
            "Epoch 61/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6507\n",
            "Epoch 62/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6758\n",
            "Epoch 63/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6412\n",
            "Epoch 64/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6320\n",
            "Epoch 65/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6583\n",
            "Epoch 66/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6597\n",
            "Epoch 67/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6427\n",
            "Epoch 68/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6440\n",
            "Epoch 69/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6704\n",
            "Epoch 70/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6459\n",
            "Epoch 71/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6420\n",
            "Epoch 72/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6547\n",
            "Epoch 73/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6251\n",
            "Epoch 74/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6261\n",
            "Epoch 75/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6593\n",
            "Epoch 76/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6481\n",
            "Epoch 77/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6474\n",
            "Epoch 78/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6287\n",
            "Epoch 79/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6253\n",
            "Epoch 80/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6158\n",
            "Epoch 81/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6051\n",
            "Epoch 82/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6352\n",
            "Epoch 83/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6140\n",
            "Epoch 84/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5976\n",
            "Epoch 85/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6160\n",
            "Epoch 86/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6253\n",
            "Epoch 87/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6224\n",
            "Epoch 88/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6055\n",
            "Epoch 89/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6030\n",
            "Epoch 90/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6016\n",
            "Epoch 91/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6054\n",
            "Epoch 92/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6212\n",
            "Epoch 93/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6176\n",
            "Epoch 94/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6110\n",
            "Epoch 95/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6094\n",
            "Epoch 96/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.6174\n",
            "Epoch 97/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6214\n",
            "Epoch 98/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6140\n",
            "Epoch 99/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6051\n",
            "Epoch 100/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6156\n",
            "Epoch 101/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6146\n",
            "Epoch 102/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6115\n",
            "Epoch 103/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6089\n",
            "Epoch 104/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6026\n",
            "Epoch 105/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6007\n",
            "Epoch 106/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.5919\n",
            "Epoch 107/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.6186\n",
            "Epoch 108/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5946\n",
            "Epoch 109/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5879\n",
            "Epoch 110/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5900\n",
            "Epoch 111/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5849\n",
            "Epoch 112/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5824\n",
            "Epoch 113/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6002\n",
            "Epoch 114/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5784\n",
            "Epoch 115/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5879\n",
            "Epoch 116/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5793\n",
            "Epoch 117/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6004\n",
            "Epoch 118/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5971\n",
            "Epoch 119/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5687\n",
            "Epoch 120/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5846\n",
            "Epoch 121/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5893\n",
            "Epoch 122/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5820\n",
            "Epoch 123/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5835\n",
            "Epoch 124/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5835\n",
            "Epoch 125/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5645\n",
            "Epoch 126/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5890\n",
            "Epoch 127/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5835\n",
            "Epoch 128/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5682\n",
            "Epoch 129/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5826\n",
            "Epoch 130/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6123\n",
            "Epoch 131/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5670\n",
            "Epoch 132/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5737\n",
            "Epoch 133/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5775\n",
            "Epoch 134/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5796\n",
            "Epoch 135/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5713\n",
            "Epoch 136/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5722\n",
            "Epoch 137/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5694\n",
            "Epoch 138/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5794\n",
            "Epoch 139/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5751\n",
            "Epoch 140/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5837\n",
            "Epoch 141/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6141\n",
            "Epoch 142/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5609\n",
            "Epoch 143/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5805\n",
            "Epoch 144/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5787\n",
            "Epoch 145/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5848\n",
            "Epoch 146/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5748\n",
            "Epoch 147/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5524\n",
            "Epoch 148/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5769\n",
            "Epoch 149/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5605\n",
            "Epoch 150/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5776\n",
            "Epoch 151/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5758\n",
            "Epoch 152/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5552\n",
            "Epoch 153/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5505\n",
            "Epoch 154/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5613\n",
            "Epoch 155/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5555\n",
            "Epoch 156/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5882\n",
            "Epoch 157/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5618\n",
            "Epoch 158/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5388\n",
            "Epoch 159/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5731\n",
            "Epoch 160/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5478\n",
            "Epoch 161/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5496\n",
            "Epoch 162/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5490\n",
            "Epoch 163/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5616\n",
            "Epoch 164/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5516\n",
            "Epoch 165/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5464\n",
            "Epoch 166/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5578\n",
            "Epoch 167/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5629\n",
            "Epoch 168/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5475\n",
            "Epoch 169/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5509\n",
            "Epoch 170/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5606\n",
            "Epoch 171/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5342\n",
            "Epoch 172/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5512\n",
            "Epoch 173/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5541\n",
            "Epoch 174/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5368\n",
            "Epoch 175/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5352\n",
            "Epoch 176/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5412\n",
            "Epoch 177/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5632\n",
            "Epoch 178/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5410\n",
            "Epoch 179/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5567\n",
            "Epoch 180/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5577\n",
            "Epoch 181/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5363\n",
            "Epoch 182/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5436\n",
            "Epoch 183/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5583\n",
            "Epoch 184/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5384\n",
            "Epoch 185/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5443\n",
            "Epoch 186/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5632\n",
            "Epoch 187/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5325\n",
            "Epoch 188/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5413\n",
            "Epoch 189/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5128\n",
            "Epoch 190/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5393\n",
            "Epoch 191/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5316\n",
            "Epoch 192/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5388\n",
            "Epoch 193/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5412\n",
            "Epoch 194/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5438\n",
            "Epoch 195/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5417\n",
            "Epoch 196/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.5362\n",
            "Epoch 197/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5283\n",
            "Epoch 198/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5549\n",
            "Epoch 199/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5320\n",
            "Epoch 200/200\n",
            "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5160\n",
            "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Mean Absolute Error on test set: 1.6541706675213637\n"
          ]
        }
      ],
      "source": [
        "# Función para crear el modelo con los mejores hiperparámetros\n",
        "def build_best_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(X_train.shape[1],)),  # Capa de entrada\n",
        "        layers.Dense(128, activation='relu'),  # Capa oculta 1 con 128 neuronas\n",
        "        layers.Dense(32, activation='relu'),   # Capa oculta 2 con 32 neuronas\n",
        "        layers.Dense(1)  # Capa de salida\n",
        "    ])\n",
        "\n",
        "    # Compilar el modelo usando el optimizador 'adam'\n",
        "    model.compile(optimizer=Adam(), loss='mean_absolute_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo usando los mejores hiperparámetros\n",
        "best_model = build_best_model()\n",
        "\n",
        "# Entrenar el modelo con batch_size=64 y epochs=200\n",
        "best_model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo con MAE\n",
        "mae_best = mean_absolute_error(y_test_r, y_pred_best)\n",
        "print(f\"Mean Absolute Error on test set: {mae_best}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best Keras Model"
      ],
      "metadata": {
        "id": "y5HmyL8_3xGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin embargo, el mejor modelo lo hemos obtenido en una de las muchas pruebas que hemos a mano. La arquitectura de la red es la siguiente:\n",
        "\n",
        "*   100 epochs\n",
        "*   Batch de 32\n",
        "*   Primera capa oculta con 64 neuronas\n",
        "*   Segunda capa oculta con 32 neuronas\n",
        "*   Optimizador Adam\n",
        "\n",
        "Este modelo nos ha proporcionado el mejor MAE sobre los datos de test, de 1.628."
      ],
      "metadata": {
        "id": "NrwcAevX34UD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL-s2q9Atxld",
        "outputId": "bd1d6173-dad4-4f74-be04-ef2c2eec294e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 17.2734\n",
            "Epoch 2/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 2.9868\n",
            "Epoch 3/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4655\n",
            "Epoch 4/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2493\n",
            "Epoch 5/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1062\n",
            "Epoch 6/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.0530\n",
            "Epoch 7/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.9886\n",
            "Epoch 8/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9438\n",
            "Epoch 9/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.8962\n",
            "Epoch 10/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.8529\n",
            "Epoch 11/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.8336\n",
            "Epoch 12/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8185\n",
            "Epoch 13/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8122\n",
            "Epoch 14/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7890\n",
            "Epoch 15/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7787\n",
            "Epoch 16/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7802\n",
            "Epoch 17/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7658\n",
            "Epoch 18/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7510\n",
            "Epoch 19/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7592\n",
            "Epoch 20/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7590\n",
            "Epoch 21/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7435\n",
            "Epoch 22/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7526\n",
            "Epoch 23/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7373\n",
            "Epoch 24/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7519\n",
            "Epoch 25/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7255\n",
            "Epoch 26/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7210\n",
            "Epoch 27/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7087\n",
            "Epoch 28/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.7308\n",
            "Epoch 29/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7340\n",
            "Epoch 30/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7153\n",
            "Epoch 31/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7072\n",
            "Epoch 32/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7174\n",
            "Epoch 33/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7269\n",
            "Epoch 34/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.7487\n",
            "Epoch 35/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7226\n",
            "Epoch 36/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7131\n",
            "Epoch 37/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7324\n",
            "Epoch 38/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7224\n",
            "Epoch 39/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6943\n",
            "Epoch 40/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7020\n",
            "Epoch 41/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7023\n",
            "Epoch 42/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6987\n",
            "Epoch 43/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6755\n",
            "Epoch 44/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7093\n",
            "Epoch 45/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6948\n",
            "Epoch 46/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7171\n",
            "Epoch 47/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6985\n",
            "Epoch 48/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6774\n",
            "Epoch 49/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.7017\n",
            "Epoch 50/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6889\n",
            "Epoch 51/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6936\n",
            "Epoch 52/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.7060\n",
            "Epoch 53/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6960\n",
            "Epoch 54/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6972\n",
            "Epoch 55/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6695\n",
            "Epoch 56/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6965\n",
            "Epoch 57/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6889\n",
            "Epoch 58/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6867\n",
            "Epoch 59/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7025\n",
            "Epoch 60/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6776\n",
            "Epoch 61/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7014\n",
            "Epoch 62/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6700\n",
            "Epoch 63/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6845\n",
            "Epoch 64/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6853\n",
            "Epoch 65/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6884\n",
            "Epoch 66/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6895\n",
            "Epoch 67/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 1.6741\n",
            "Epoch 68/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7018\n",
            "Epoch 69/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6754\n",
            "Epoch 70/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6759\n",
            "Epoch 71/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6635\n",
            "Epoch 72/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6819\n",
            "Epoch 73/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.6645\n",
            "Epoch 74/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6739\n",
            "Epoch 75/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6707\n",
            "Epoch 76/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6653\n",
            "Epoch 77/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6501\n",
            "Epoch 78/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6465\n",
            "Epoch 79/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6367\n",
            "Epoch 80/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6515\n",
            "Epoch 81/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6470\n",
            "Epoch 82/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6248\n",
            "Epoch 83/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6436\n",
            "Epoch 84/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6344\n",
            "Epoch 85/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6324\n",
            "Epoch 86/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6190\n",
            "Epoch 87/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6283\n",
            "Epoch 88/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6250\n",
            "Epoch 89/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6069\n",
            "Epoch 90/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.6342\n",
            "Epoch 91/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.6156\n",
            "Epoch 92/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6095\n",
            "Epoch 93/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6277\n",
            "Epoch 94/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6257\n",
            "Epoch 95/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6151\n",
            "Epoch 96/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5808\n",
            "Epoch 97/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.6029\n",
            "Epoch 98/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6096\n",
            "Epoch 99/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.5959\n",
            "Epoch 100/100\n",
            "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.5990\n",
            "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Mean Absolute Error for y_pred: 1.6282342567171122\n"
          ]
        }
      ],
      "source": [
        "# Define the Neural Network model\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
        "    layers.Dense(64, activation='relu'),  # Hidden layer\n",
        "    layers.Dense(32, activation='relu'),  # Another hidden layer\n",
        "    layers.Dense(1)  # Output layer\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)  # Adjust epochs and batch_size as needed\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabe destacar quee intentamos añadir capas de dropout en la red, pero empeoraban el error. Probablemente se deba a que estamos tratando con una red muy pequeña."
      ],
      "metadata": {
        "id": "iXFExEz24iHl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbdjnsTxbAp"
      },
      "source": [
        "### Red de Neuronas (MLPRegressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, probamos otra red de neuronas, en este caso un *MLPRegressor*. Esta red tendrá una única capa oculta.\n",
        "Ajustamos los siguientes hiperparámetros mediante *RandomizedSearchCV*:\n",
        "\n",
        "\n",
        "\n",
        "*   **hidden_layer_sizes:** número de neuronas en la capa oculta\n",
        "*   **solver:** optimizador del modelo para el ajuste de parámetros en el entrenamiento.\n",
        "*   **alpha:** valor del hiperparámetro de la regularización L2, una técnica para reducir el overfitting.\n",
        "*   **max_iter:** número de epochs."
      ],
      "metadata": {
        "id": "7TShu-FF4xul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlNIHWKfpyn2",
        "outputId": "e62694c7-8334-4d96-ed8d-eac1d4dad44a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score:  -1.8238276780890612\n",
            "Best Parameters : {'solver': 'adam', 'max_iter': 500, 'hidden_layer_sizes': 200, 'alpha': 0.35000000000000003}\n",
            "CV Results:  {'mean_fit_time': array([17.58362207, 40.61703763, 61.59212222, 43.13875132, 55.59276347]), 'std_fit_time': array([ 4.24540745, 21.29543879,  8.91683407,  4.522613  , 20.56658598]), 'mean_score_time': array([0.00483322, 0.00599322, 0.01118193, 0.00563693, 0.01095567]), 'std_score_time': array([0.00155386, 0.0001756 , 0.00103705, 0.00202193, 0.00116125]), 'param_solver': masked_array(data=['sgd', 'sgd', 'adam', 'adam', 'sgd'],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_max_iter': masked_array(data=[500, 1000, 500, 500, 500],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value=999999), 'param_hidden_layer_sizes': masked_array(data=[50, 100, 200, 50, 200],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value=999999), 'param_alpha': masked_array(data=[0.1, 0.0, 0.35000000000000003, 0.45, 0.4],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value=1e+20), 'params': [{'solver': 'sgd', 'max_iter': 500, 'hidden_layer_sizes': 50, 'alpha': 0.1}, {'solver': 'sgd', 'max_iter': 1000, 'hidden_layer_sizes': 100, 'alpha': 0.0}, {'solver': 'adam', 'max_iter': 500, 'hidden_layer_sizes': 200, 'alpha': 0.35000000000000003}, {'solver': 'adam', 'max_iter': 500, 'hidden_layer_sizes': 50, 'alpha': 0.45}, {'solver': 'sgd', 'max_iter': 500, 'hidden_layer_sizes': 200, 'alpha': 0.4}], 'split0_test_score': array([-2.82490841, -2.81648204, -1.85085532, -1.82964073, -1.8188754 ]), 'split1_test_score': array([-2.79372257, -2.78837464, -1.82811632, -1.82020322, -1.83106503]), 'split2_test_score': array([-2.79054784, -1.78487897, -1.79289562, -1.82844021, -2.01933141]), 'split3_test_score': array([-1.99567123, -1.802368  , -1.82691308, -1.83872538, -1.81380442]), 'split4_test_score': array([-2.81040826, -1.80384725, -1.82035804, -1.83353043, -1.84296216]), 'mean_test_score': array([-2.64305166, -2.19919018, -1.82382768, -1.83010799, -1.86520768]), 'std_test_score': array([0.32392541, 0.49266728, 0.01858621, 0.00611681, 0.07772217]), 'rank_test_score': array([5, 4, 1, 2, 3], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "MLP = MLPRegressor()\n",
        "\n",
        "# Definir distintos valores de los parámetros\n",
        "param_grid_MLP = {'hidden_layer_sizes': [50, 100, 200],\n",
        "                  'solver': ['sgd', 'adam'],\n",
        "                  'alpha': np.arange(0, 1, 0.05),\n",
        "                  'max_iter': [500, 1000]}\n",
        "\n",
        "rand_MLP = RandomizedSearchCV(estimator=MLP, param_distributions=param_grid_MLP, n_iter=5, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "# rand_MLP = GridSearchCV(estimator=MLP, param_grid=param_grid_MLP, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_MLP.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "print('Best Score: ', rand_MLP.best_score_)\n",
        "print('Best Parameters :', rand_MLP.best_params_)\n",
        "print('CV Results: ', rand_MLP.cv_results_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best MLPRegressor"
      ],
      "metadata": {
        "id": "xxKLzywg7dfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo con los hiperparámetros que hemos encontrado y lo probamos sobre los datos de test.\n",
        "En este caso al final nos dimos cuenta de que obteniamos mejores resultados con el solver 'adam'. Esto seguramente es debido a que n_iter era bajo y no llegó a probar esta combinación\n"
      ],
      "metadata": {
        "id": "g7HQOLM17hZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ho96fTEJYm",
        "outputId": "5423b600-1d85-4b8c-9604-f1c5b1c97b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 1.8166929505250877\n"
          ]
        }
      ],
      "source": [
        "MLP = MLPRegressor(hidden_layer_sizes=(200,),\n",
        "                   max_iter=1000,  # Increase the max iterations\n",
        "                   solver='sgd',  # Optimizer\n",
        "                   learning_rate_init=0.001,  # Adjust learning rate\n",
        "                   random_state=42)\n",
        "\n",
        "MLP.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Hacer predicciones con los datos de prueba\n",
        "y_pred = MLP.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el MAE es de 1.817. Sigue siendo un error menor que el del árbol de decisión pero es peor que el de la red de *Keras*. Probablemente esto se deba a que la arquitectura de nuestras dos redes es distinta, y también es posible que al estar implementadas en librerías diferentes, existan algunos detalles en las implementaciones internas que no sean iguales."
      ],
      "metadata": {
        "id": "tAoXlk3Q7l74"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTryk9u4x6L3"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a pasar a probar distintos ensembles para intentar mejorar los distintos resultados que hemos obtenido. Dentro de los ensembles homogéneos, que usan como base el mismo tipo de modelo, el primero que probaremos será el *Random Forest*, que usa árboles de decisión como base.\n",
        "\n",
        "Hemos ajustado los siguientes hiperparámetros mediante *GridSearchCV*:\n",
        "\n",
        "\n",
        "*   **n_estimators:** número de árboles de decisión\n",
        "*   **max_features**: proporción de los atributos que se tienen en cuenta para dividir un nodo.\n",
        "*   **min_samples_split**: número de datos que hacen falta para dividir un nodo.\n",
        "\n"
      ],
      "metadata": {
        "id": "CRm--kjR8iEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fz3HkkT3x6L3",
        "outputId": "bc282b91-f2bf-4b65-ba40-d7ca60213f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.9988038188342607\n",
            "{'max_features': 1.0, 'min_samples_split': 3, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Definir distintos valores de los parámetros\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200],\n",
        "               'max_features': [0.5, 1.0],\n",
        "               'min_samples_split': [2,3,5]}\n",
        "\n",
        "# rand_RF = RandomizedSearchCV(estimator=rf, param_distributions=param_grid_rf, n_iter=5, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_RF = GridSearchCV(estimator=rf, param_grid=param_grid_rf, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_RF.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# resultados\n",
        "best_score = rand_RF.best_score_\n",
        "best_params = rand_RF.best_params_\n",
        "\n",
        "print(best_score)\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q6zVOMYx8z4"
      },
      "source": [
        "#### Best RF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora entrenamos el mejor modelo."
      ],
      "metadata": {
        "id": "8ExhhF8V9qch"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejwpkj__namn",
        "outputId": "301a70d4-3e23-4d19-98b8-2ea3f04f85fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 2.0338967036985207\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(random_state=42, max_features=1.0, min_samples_split=3, n_estimators=200)\n",
        "\n",
        "rf.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos obtenido un MAE de 2.033 sobre los datos de test. Las redes de neuronas siguen dando mejores resultados, pero hemos conseguido mejorar el error del árbol de decisión."
      ],
      "metadata": {
        "id": "SLcRP70_9bKu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG8wuxAfyIm_"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vale siguiendo con los ensembles tambien probamos el Gradient Boosting regressor, que como hemos visto en clase, los métodos de boosting entrenan modelos de forma secuencial.\n",
        "\n",
        "Gradient boosting entrena una serie de árboles de decisión.\n",
        "\n",
        "A traves de una randomized search de los parámetros vimos que lo mejor era usar un número elevado de optimizadores (800), además de otros parámetros, obteniendo así un error medio absoluto de 2.07"
      ],
      "metadata": {
        "id": "wYXheCSQDuy7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPJpAf_yvnNb",
        "outputId": "67b63298-4cdb-4eea-c1fd-79984325f896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-2.056489326724912\n",
            "{'n_estimators': 800, 'min_samples_split': 5, 'max_features': 1.0}\n"
          ]
        }
      ],
      "source": [
        "GB = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Definir distintos valores de los parámetros\n",
        "param_grid_gb = {'n_estimators': [200, 400, 600, 800],\n",
        "               'max_features': [0.5, 1.0],\n",
        "               'min_samples_split': [2, 5]}\n",
        "\n",
        "# Busqueda de hiperparámetros\n",
        "rand_GB = RandomizedSearchCV(estimator=GB, param_distributions=param_grid_gb, scoring='neg_mean_absolute_error', cv=5, verbose=False)\n",
        "rand_GB.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# resultados\n",
        "best_score = rand_GB.best_score_\n",
        "best_params = rand_GB.best_params_\n",
        "\n",
        "print(best_score)\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVL5lhPqzQmZ"
      },
      "source": [
        "#### Best GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxHI9nNEu1m6",
        "outputId": "031bfe90-5c15-446a-fe19-e49bcedac5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 2.078713938637538\n"
          ]
        }
      ],
      "source": [
        "GB = GradientBoostingRegressor(random_state=42, max_features=1.0, min_samples_split=5, n_estimators=800)\n",
        "\n",
        "GB.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "y_pred = GB.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plM3s_vozkYu"
      },
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego probamos el AdaBoost para regresión. Este se enfoca en los errores de predicción de los modelos anteriores y asigna más peso a las observaciones que los modelos iniciales no predijeron bien, a las más difíciles de predecir.\n",
        "\n",
        "Lo probamos utilizando diferentes modelos como estimadores pero obtuvimos los mejores resultados con la red MLP regressor, obteniendo un MAE de 2,27\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AyAc0CuMD-Yq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmuF4q9-bIBh",
        "outputId": "6ded9784-c916-4d72-ef26-2c3fb6008332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.270971365854697\n"
          ]
        }
      ],
      "source": [
        "# AdaBoost wrapper\n",
        "ada_mlp = AdaBoostRegressor(estimator=MLPRegressor(hidden_layer_sizes=(200,),\n",
        "                   max_iter=1000,  # Increase the max iterations\n",
        "                   solver='sgd',  # Optimizer\n",
        "                   learning_rate_init=0.001,  # Adjust learning rate\n",
        "                   random_state=42), n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the AdaBoost model\n",
        "ada_mlp.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Make predictions\n",
        "y_pred_adaMLP = ada_mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "mae = mean_absolute_error(y_test, y_pred_adaMLP)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwIO_muUzrIZ"
      },
      "source": [
        "### Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También probamos con el Bagging Regressor, que crea múltiples versiones de un modelo (en este caso, una Red Neuronal MLP) y promedia sus predicciones.\n",
        "\n",
        "Al igual que con el AdaBoost, probamos utilizando como estimadores árboles de decisión, random forest... pero lo que funcionó mejor fue la red MLP, que nos dio un error de 1,77.\n",
        "\n",
        "Por ahora el mejor resultado junto con la red de Keras.\n"
      ],
      "metadata": {
        "id": "rO_hOPgKEg2R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymtrkeKyOTYu",
        "outputId": "765a71de-2b4a-42df-93dc-2d844fd28f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for Bagging Regressor: 1.7762797388367317\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the Bagging Regressor\n",
        "bagging_regressor = BaggingRegressor(\n",
        "    estimator=MLPRegressor(hidden_layer_sizes=(200,),\n",
        "                   max_iter=1000,  # Increase the max iterations\n",
        "                   solver='sgd',  # Optimizer\n",
        "                   learning_rate_init=0.001,  # Adjust learning rate\n",
        "                   random_state=42),  # Default is DecisionTreeRegressor\n",
        "    n_estimators=50,      # Number of base estimators in the ensemble\n",
        "    random_state=42       # Ensures reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "bagging_regressor.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_bagging = bagging_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for the Bagging Regressor\n",
        "mae_bagging = mean_absolute_error(y_test_r, y_pred_bagging)\n",
        "print(f\"Mean Absolute Error for Bagging Regressor: {mae_bagging}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LwLBGEPeG3D"
      },
      "source": [
        "### Voting Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También probamos ensembles heterogéneos que mezclan diferentes tipos de modelos, combinando sus predicciones: Voting y Stacking Regressors\n",
        "\n",
        "Para ambos metimos como estimadores modelos que ya habíamos entrenado: (lr', linear regression) , ('dt', arbol de decision), ('rf', random forest) y ('MLP', Red MLP)\n"
      ],
      "metadata": {
        "id": "WArx679uFFIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b09fIeuweI7J",
        "outputId": "29163b07-0d14-4772-96cc-ba9cef230173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 1.8166929505250877\n"
          ]
        }
      ],
      "source": [
        "# Training classifiers\n",
        "voting = VotingRegressor(estimators=[('lr', lr), ('dt', arbol_decision), ('rf', rf), ('MLP', MLP)])\n",
        "voting = voting.fit(X_train, y_train.values.ravel())\n",
        "# Hacer predicciones con los datos de prueba\n",
        "y_pred = MLP.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDXeTm3Wej-D"
      },
      "source": [
        "### Stacking Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En ambos el MAE que hemos obtenido es el mismo que en la MLP por si sola.\n",
        "\n",
        "Lo que pensamos que indica que la MLP es significativamente más fuerte que los otros modelos y termina dominando en las predicciones combinadas.\n"
      ],
      "metadata": {
        "id": "2DjtbROqFnLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RDb8ODNemGv",
        "outputId": "616b3d63-e444-4255-dd2d-1b35b550fdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error for y_pred: 1.8166929505250877\n"
          ]
        }
      ],
      "source": [
        "# Training classifiers\n",
        "stacking = StackingRegressor(estimators=[('lr', lr), ('dt', arbol_decision), ('rf', rf), ('MLP', MLP)], final_estimator=RidgeCV())\n",
        "stacking = stacking.fit(X_train, y_train.values.ravel())\n",
        "# Hacer predicciones con los datos de prueba\n",
        "y_pred = MLP.predict(X_test)\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error for y_pred: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como conclusiones del trabajo de regresión:\n",
        "\n",
        "- El mejor resultado lo obtuvimos con la Red nauronal de Keras.\n",
        "\n",
        "- Los modelos de ensembles ofrecen buenos resultados pero no superan a la red, lo que demuestra que el patrón no lineal de los datos se captura mejor con la red que con otros modelos.\n",
        "\n",
        "- Para todos los modelos la optimización de hiperparámetros mejoró el rendimiento.\n",
        "\n",
        "- Los ensembles funcionan mejor cuando los modelos base aportan diversidad. Si un solo modelo como el MLP es dominante, las mejoras no son significativas.\n"
      ],
      "metadata": {
        "id": "vOokTlIZGDJL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dG8wuxAfyIm_",
        "plM3s_vozkYu",
        "IwIO_muUzrIZ",
        "4LwLBGEPeG3D",
        "KDXeTm3Wej-D"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
